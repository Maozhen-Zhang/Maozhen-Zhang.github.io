---
layout: post
title: 差分隐私(二)-联邦下的差分隐私类别
date: 2023-03-25 12:52:00
description: 差分隐私与联邦学习的结合
tags: Privacy Research
categories: Differential-Privacy Research-Base
---



# 差分隐私的类别

联邦场景下客户端级别的类型：

1. 样本级别（element-level）的差分隐私：训练的模型，不会泄露某个特定的样本是否参与了训练
2. 用户级别（client-level）的差分隐私：训练的模型，不会泄露某个用户是否参与了训练



**样本级别**(即CCS2016,deep learning with differential privacy)：

> 是在通常的SGD的一个batch训练过程中，增加了DP的两个步骤。在一个batch根据损失函数计算完梯度之后，在进行梯度下降的更新前，第一步是对每个样本计算的梯度裁剪，第二步是在这个batch的梯度更新前对梯度更新总值添加噪声。对梯度进行放缩，让梯度的二范数值在范围C内，之后添加的噪声的大小和C值有关。C值是一个动态变化的值，文章中提出，C的值选取为这个batch梯度的范数中位数值

<img src="https://mz-pico-1311932519.cos.ap-nanjing.myqcloud.com/image/image-20230315101320207.png" alt="image-20230315101320207" style="zoom:25%;" />

联邦学习场景下的**用户级别**差分隐私，包括三个步骤，①裁剪②聚合③加噪

> 联邦聚合FedAvg，每个用户返回梯度的更新值$\theta^\prime-\theta_t$给服务器，服务器做加权聚合

<img src="https://mz-pico-1311932519.cos.ap-nanjing.myqcloud.com/image/image-20230315101714927.png" alt="image-20230315101714927" style="zoom:25%;" />

联邦学习的差分隐私包含两个步骤都是由服务器完成：①梯度裁剪②添加噪声

> 客户端做完本地的SGD得到梯度更新值，服务器不是直接对梯度更新值进行聚合，而是进行梯度裁剪，与之前样本集的差分隐私类似，二范数限制取所有用户更新值的中位数值。

<img src="https://mz-pico-1311932519.cos.ap-nanjing.myqcloud.com/image/image-20230315111028793.png" alt="image-20230315111028793" style="zoom:25%;" />

> 服务器对进行范数限制的梯度更新值进行加权聚合

<img src="https://mz-pico-1311932519.cos.ap-nanjing.myqcloud.com/image/image-20230315111449054.png" alt="image-20230315111449054" style="zoom:25%;" />

> 第二个差分隐私步骤是添加噪声，添加噪声的强度与用户梯度更新范数值中位数S有关。在聚合平均之后，服务器添加高斯噪声，然后做模型参数的全局更新。

<img src="https://mz-pico-1311932519.cos.ap-nanjing.myqcloud.com/image/image-20230315133707442.png" alt="image-20230315133707442" style="zoom:25%;" />

**完整算法：**

<img src="https://mz-pico-1311932519.cos.ap-nanjing.myqcloud.com/image/image-20230315134106714.png" alt="image-20230315134106714" style="zoom:25%;" />