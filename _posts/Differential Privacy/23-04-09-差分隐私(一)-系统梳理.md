---
layout: post
title: 差分隐私(一)-系统梳理
date: 2023-03-20 12:52:00
description: 差分隐私的基础概念解析
tags: Privacy
categories: Differential-Privacy
---



# 差分隐私

[Programming Differential Privacy](https://programming-dp.com/cn/cover.html)

[差分隐私-知乎文章](https://zhuanlan.zhihu.com/p/425732159)

## 噪声、敏感度、隐私预算

差分隐私约束：
$$
Pr[M(d)\in S]\le e^\epsilon Pr[M(d^\prime)\in S]+\delta
$$
噪声：$$Y\sim L(0,\frac{\Delta f}{\epsilon})$$

敏感度：$$\Delta f$$

隐私预算：$$\epsilon$$



## 概念解释

公式$$Pr[M(d)\in S]$$：

> 随机变量$$\mathcal M(d)$$的曲直落在集合$$S$$的概率
>
> 此处$$Pr[M(d)\in S]$$表示原数据，$$Pr[M(d^\prime)\in S]$$表示经过差分隐私加噪处理后的数据
>
> 通过对比这两个输出结果落到$$S$$中的概率得到这两个的差别
>
> 因此$$\epsilon$$越小，代表加噪之后的数据与原数据越像，隐私保护的效果越好。



敏感度：$$\Delta f$$，指的是数据集$$D$$中两个相邻的子集合$$\mathcal D_1,\mathcal D_2$$的区别(多一条数据/少一条数据的输出变化)

> 深度学习中，因为梯度是一个无界的问题，因此需要人为限制阈值$$\Delta$$
> 我认为是限制最大的梯度值，这样$$epoch=t$$中的两个batch之间的区别（敏感度）最大就是$$\Delta^t$$



隐私预算：$$\epsilon$$

> 隐私预算越小，噪声越大，结果可用性越小，隐私保护越好。

## 不同的差分隐私机制

### Laplace mechanism

Laplace机制提供的是严格的$$(\epsilon,0)$$-DP
$$
Pr[M(d)\in S]\le e^\epsilon Pr[M(d^\prime)\in S]
$$
概率密度分布：
$$
f(x \mid \mu, b)=\frac{1}{2 b} \exp \left(-\frac{|x-\mu|}{b}\right)=\frac{1}{2 b} \begin{cases}\exp \left(-\frac{\mu-x}{b}\right) & x<\mu \\ \exp \left(-\frac{x-\mu}{b}\right) & x \geq \mu\end{cases}
$$
$$\Delta f$$：
$$
\triangle f=\max _{x, y \in \mathbb{N} \mid{ }^{|x|},\|x-y\|_1=1}\|f(x)-f(y)\|_1
$$
定义：噪声$$Y\sim L(0,\frac{\Delta f}{\epsilon})$$满足$$(\epsilon,0)$$-差分隐私

> $$p_x$$表示$$\mathcal M_L(x,f,\epsilon)$$的pdf，$$p_y$$表示$$\mathcal M_L(x,f,\epsilon)$$的pdf
>
> 对于某个输出$$z$$，约束$$MaxDivergence\le\epsilon$$
>
> 根据$$Lap(0,\frac{\Delta f}{\epsilon})$$可以得到Laplace分布:
>
> $$ f(x|\mu,b)=\frac{\epsilon}{2\Delta f}exp(-\frac{\vert x\vert\epsilon}{\Delta f}) $$

$$
\begin{aligned} \frac{p_x(z)}{p_y(z)} & =\prod_{i=1}^k \frac{\exp \left(-\frac{\epsilon\left|f(x)_i-z_i\right|}{\Delta f}\right)}{\exp \left(-\frac{\epsilon\left|f(y)_i-z_i\right|}{\Delta f}\right)} \\ & =\prod_{i=1}^k \exp \frac{\epsilon\left(\left|f(y)_i-z_i\right|-\left|f(x)_i-z_i\right|\right)}{\Delta f} \\ & \leq \prod_{i=1}^k \exp \left(\frac{\epsilon\left(\left|f(x)_i-f(y)_i\right|\right)}{\triangle f}\right) \\ & =\exp \left(\frac{\epsilon \cdot\|f(x)-f(y)\|_1}{\triangle f}\right) \\ & \leq \exp (\epsilon)\end{aligned}
$$

### Gaussian mechanism

高斯机制提供的是松弛的$$(\epsilon,\delta)$$-DP
$$
Pr[M(d)\in S]\le e^\epsilon Pr[M(d^\prime)\in S]+\delta
$$
高斯噪声分布：

> $$\sigma^2$$的开平方或标准差$$\sigma$$等于尺度参数，决定分布幅度

$$
f(x)=\frac{1}{\sigma\sqrt{2\pi}}e^{-\frac{(x-\mu)^2}{2\sigma^2}}
$$

对于任意$$\epsilon\in(0,1)，\delta\ge\frac{e^{-(\sigma\epsilon)^2/2}}{1.25}$$，有噪声$$Y\sim\mathcal N(0,\Delta f^2\sigma^2)$$满足$$(\epsilon,\delta)$$-差分隐私

> 高斯分布的标准差$$\sigma$$，决定噪声的尺度
>
> $$\epsilon$$表示隐私预算，和噪声负相关



在松弛的差分隐私中，输出为两部分，一部分严格遵守DP，一部分违反DP

> 输出集合分隔成两部分，第一部分被$$\epsilon$$约束住，第二部分小于$$\delta$$
>
> $$S_1$$表示遵守严格DP的部分，$$S_2$$表示违反严格DP的部分

$$
$\begin{array}{r}\underset{x \sim \mathcal{N}\left(0, \sigma^2\right)}{\operatorname{Pr}}[f(x)+x \in S]=\underset{x \sim \mathcal{N}\left(0, \sigma^2\right)}{\operatorname{Pr}}\left[f(x)+x \in S_1\right] \\ +\underset{x \sim \mathcal{N}\left(0, \sigma^2\right)}{\operatorname{Pr}}\left[f(x)+x \in S_2\right] \\ \leq \underset{x \sim \mathcal{N}\left(0, \sigma^2\right)}{\operatorname{Pr}}\left[f(x)+x \in S_1\right]+\delta \\ \leq e^\epsilon\left(\underset{x \sim \mathcal{N}\left(0, \sigma^2\right)}{\operatorname{Pr}}\left[f(y)+x \in S_1\right]+\delta\right)\end{array}$
$$



## 组合定理

## 基础组合定理

> 不考虑查询函数之间的关联性（查询相互独立）
>
> 1. 并行组成 **不相交数据集，不同查询**
> 2. 串行组成 **同一数据集，不同查询**

Sequential Composition

Parallel Composition

### 高级组合定理

> 考虑查询函数之间的关联性

Navie Composition Theorem

Strong Composition Theorem

Moments Accountant

