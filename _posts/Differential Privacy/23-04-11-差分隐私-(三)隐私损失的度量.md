# 隐私损失

差分隐私中常用的隐私损失度量

1. Renyi 散度：Renyi 散度是一种用于度量两个概率分布之间的差异的方法，可以用于计算差分隐私中的隐私损失。Renyi 散度在差分隐私中被广泛应用，它可以用于衡量隐私预算的耗尽情况，例如计算 epsilon 和 delta。
2. Fisher 信息：Fisher 信息是一种度量随机变量关于参数的信息量的方法，可以用于计算差分隐私中的隐私损失。Fisher 信息在差分隐私中常常用于计算敏感性的上界，从而用于确定噪声的大小。
3. Moments Accountant：Moments Accountant 是一种常用的差分隐私计算方法，用于估计累积隐私预算的消耗情况。Moments Accountant 基于矩的概念，通过计算梯度和噪声的高阶矩来估计隐私损失。
4. 高斯机制：高斯机制是一种常用的差分隐私机制，其中噪声服从高斯分布。可以通过计算高斯噪声的方差来估计差分隐私的损失。根据隐私参数的选择，可以计算 epsilon 和 delta。

一些拓展方法：

1. Moments Accountant with Sampling：这是 Moments Accountant 的一种改进方法，通过对数据集进行采样，从而减少计算高阶矩的开销，提高计算效率。
2. Rényi Divergence with Rényi Privacy：这是一种使用 Rényi 散度来计算隐私损失的方法，其中 Rényi Privacy 是一种改进的隐私度量方式，可以根据具体的隐私需求来选择不同的 Rényi 参数。
3. Pufferfish Privacy：这是一种新型的差分隐私计算方法，使用 Pufferfish Privacy 框架，通过对梯度向量进行量化和随机化，从而计算隐私损失。
4. Zero-Concentrated Differential Privacy (ZCDP)：这是一种用于计算差分隐私损失的方法，特点是在计算梯度的高阶矩时，考虑了零集中差分隐私的特性，从而提高计算效率。

选择的场景因素：

1. 隐私保护需求：不同的差分隐私度量方法适用于不同的隐私保护需求。例如，如果需要量化隐私泄露的严重性，并且关注个别记录的隐私保护，可以选择使用基于单个隐私泄露的度量方法，如最大化泄露概率 (maximal leakage) 或最大化后验概率 (maximal posterior probability)。而如果关注整体隐私保护效果，可以选择使用基于全局隐私泄露的度量方法，如全局灵敏度 (global sensitivity) 或隐私预算 (privacy budget)。
2. 数据集和模型属性：不同的数据集和模型属性可能对隐私度量方法的选择产生影响。例如，如果数据集的规模较大，可以选择计算代价较低的隐私度量方法，如 Moments Accountant with Sampling；如果数据集的规模较小，可以选择计算代价较高但更精确的隐私度量方法，如 Rényi Divergence with Rényi Privacy。另外，不同类型的模型，如深度神经网络、逻辑回归、决策树等，可能对隐私度量方法的适用性产生影响。
3. 计算效率和实际可行性：隐私度量方法的计算效率和实际可行性也是选择的考虑因素。一些隐私度量方法可能计算复杂度较高，需要较大的计算资源和时间，因此在实际应用中可能不太可行。在实际场景中，需要考虑计算效率和实际可行性，选择适合具体场景的隐私度量方法。
4. 具体应用场景：不同的应用场景可能对隐私度量方法的选择产生影响。例如，在医疗、金融等涉及敏感数据的领域中，对隐私保护要求较高，可能需要选择更为精确和严格的隐私度量方法；而在一些非敏感数据应用场景中，可以选择计算代价较低但足够保护隐私的度量方法。



# Composition Theorem

深度学习系统在经过一轮subsample，梯度计算，梯度裁剪，高斯加噪组成的训练后，得到了一组满足$(\epsilon,\delta)$-DP的参数$\theta_t$，然后将$\theta_t$作为初始参数进行下一轮训练，经过$T$轮训练后，模型收敛。假设整个训练过程是公开的，即从第一到第$T$轮的所有模型参数都是可以获取的，那么怎么判断损失？

Composition Theorem：计算整个训练系统的差分隐私损失。一个直觉是，一个由$T$个满足$(\epsilon,\delta)-DP$的机制$\mathcal M_t$组成的队列系统$\mathcal M$的隐私损失最多是$(T\epsilon,T\delta)$

这个损失是否还能够再次减少，Strong Compposition theorem提出，$T$个机制Composition后，隐私损失变为$(\tilde \epsilon,\tilde \delta)$
$$
\tilde{\epsilon}=\epsilon\sqrt{2T\ln(1/\delta')}+T\epsilon\frac{e^{\epsilon}-1}{e^{\epsilon}+1};\\\tilde{\delta}=T\delta+\delta'
$$
一般取$\delta^\prime=\delta$，结合subsample定理，当$\epsilon\rightarrow 0$时，Strong Composition给出了$(\mathcal{O}(q\epsilon\sqrt{T\ln(1/\delta)},q(T+1)\delta)$的隐私损失

> 这个隐私损失与$\delta$相关，当$\delta$很小时，该损失变得非常大
>
> 因此16年提出了Moments Account，

Moments Account将深度学习的训练过程中Composition的隐私损失边界降低到$(q\epsilon\sqrt{T},\delta)$

> 该隐私损失边界的基本思想是将每一轮训练的隐私损失看成随机变量，将总隐私损失看成各轮随机变量的加和分布，通过计算随机变量的矩生成函数moment generating function，得到更精准的隐私界
>
> 该方法最终可以归为RDP计算，在高斯机制下具有解析解