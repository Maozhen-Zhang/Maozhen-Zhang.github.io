---
layout: post
title: 深度学习代码理解
date: 2023-02-28 12:52:00
description: comprehend python and deep learning come
tags: Code
categories: Code-Comprehend Deep-Learning
title: 深度学习代码理解(更新中...)



# 深度学习

## 卷神经网络pytorch

**数据**

1. 数据处理(os，torch.utils.data.Dataset)

2. 数据变换(torchvision.transforms)

3. 数据增强(mixup拼接,cutout裁剪,cutmix融合前面两种方法)

**模型**

1. Torchvision.model

**优化器及loss**

1. optimizer
2. loss

**训练**

## 数据集构建

使用自己的`x_train`和`y_train`构建数据集

```python
#继承并重写
class Mydataset(Data.Dataset):
  def __init__(self):#将变量放入
    self.x_train = x_train
    self.y_label = y_label
  def __getitem__(self, idx):
    return self.x_train[idx], self.y_label[idx]
  def __len__(self):#返回长度
    return len(self.y_train)
 
#使用 MyDataset，一次只能获取一个样本
#使用了Dataloader，一次能获取一批
train_dataset = MyDataset(x_train, y_train)
train_loader = Data.Dataloader(train_dataset, batch_size=16, shuffle=True)
```

### DataLoader详解

### 使用：

1. 创建一个`Dataset`对象
2. 创建一个`DataLoader`对象
3. 循环这个`DataLoader`对象，将xx、xx加载到模型中训练

```python
torch.utils.data.DataLoader(dataset, batch_size=1, shuffle=False, sampler=None,
batch_sampler=None, num_workers=0, collate_fn=None,
pin_memory=False, drop_last=False, timeout=0,
```

> `dataset(Dataset)`: 传入的数据集
> `batch_size(int, optional)`: 每个batch有多少个样本
> `shuffle(bool, optional)`: 在每个epoch开始的时候，对数据进行重新排序
> `sampler(Sampler, optional)`: 自定义从数据集中取样本的策略，如果指定这个参数，那么shuffle必须为False
> `batch_sampler(Sampler, optional)`: 与sampler类似，但是一次只返回一个batch的indices（索引），需要注意的是，一旦指定了这个参数，那么batch_size,shuffle,sampler,drop_last就不能再指定了（互斥——Mutually exclusive）
> `num_workers (int, optional)`: 这个参数决定了有几个进程来处理data loading。0意味着所有的数据都会被load进主进程。（默认为0）
> `collate_fn (callable, optional)`: 将一个list的sample组成一个mini-batch的函数
> `pin_memory (bool, optional)`： 如果设置为True，那么data loader将会在返回它们之前，将tensors拷贝到CUDA中的固定内存（CUDA pinned memory）中.
> `drop_last (bool, optional)`: 如果设置为True：这个是对最后的未完成的batch来说的，比如你的batch_size设置为64，而一个epoch只有100个样本，那么训练的时候后面的36个就被扔掉了…
> 如果为False（默认），那么会继续正常执行，只是最后的batch_size会小一点。
> `timeout(numeric, optional)`: 如果是正数，表明等待从worker进程中收集一个batch等待的时间，若超出设定的时间还没有收集到，那就不收集这个内容了。这个numeric应总是大于等于0。默认为0

## 模型构建

```python
class MyModel(nn.Model):
  def __init__(self, x):
    super(MyModel, self).__init__()
    self.linear1 = nn.Lineear(10, 64)
    self.activation = nn.ReLU()
    self.linear2 = nn.Linear(64, 8)#可以改写非耦合
    self.linear3 = nn.lieanr(8,4)
  def forward(self, x):
    output = self.linear1(x)	#=>[batch_size, 64]
    output = self.activation(output)	#=>[batch_size,64]
    output = self.linear2(output)	#=>[batch_size,8]
    output = self.lienar3(output)	#=>[batch_size,4]
   
model = MyModel(x)
loss_fn = nn.CrossEntropyloss
optimizer = optim.Adam()

```

## 模型运行

```python
Epoch = 10
for epoch in range(Epoch):
  for x, y in train_loader:
    pred = model(x)
    loss = loss_fn(pred, y) #这里期望要long类型，y的类型需要注意
    
    loss.backward()
    optimizer.step()
    optimizer.zero_grad()
```

模型训练时整体内容： 

```python
#外层epoch循环
for e in range(args.epochs):
  running_loss = 0 #记录每轮epoch的损失
  #遍历dataloader，里面的data是batch
  for i,data in enumerate(train_loader):
    #data[0]是输入数据，data[1]是标签
    inputs, labels = data[0].to(device), data[1].to(device)
  
    #一些方法的获取和初始化
    #损失函数
    criterion = nn.CrossEntropyLoss()  # 交叉熵损失
    #优化器>>>实现随机梯度下降算法,lr– 学习率,momentum– 动量因子
    optimizer = optim.SGD(net.parameters(), lr=0.001, momentum=0.9)  
    optimizer.zero_grad()#调用backward()之前要将梯度清零
  
		#向前、向后、优化
    outputs = net(inputs)							#前向
		loss = criterion(outputs, labels)	#求损失操作：将输出和标签输入
    loss.backward()										#损失向输入测进行反向传播>>>将梯度积累到x.grad中备用
    optimizer.step()									#优化器对x值进行更新，
```

# 自动编码器

自动编码器是神经网络中的一种，基本思想是使用一层或多层神经网络对输入数据进行行摄，得到输出向量，作为从输入数据提取出的特征。

传统自编码器一般用来数据降维或着特征学习，如PCA，但是自动编码器比PCA灵活，它既能表征线性变换又能表征非线性变换。

自动编码器可以看做是前馈网络的一个特例。基本的子编码器是一个简单的三层神经网络结构：一个输入层、一个隐藏层和一个输出层，其中输出层和输入层具有相同的维数。

自编码器，它的输入输出是一致的，目标是使用稀琉的高阶特征重新组合来重构自己。自动编码器是一种数据压缩算法，其中数据的压缩和解压缩函数是数据相关的、有损的、从样本中自动学习。

目前自编码器的两个主要用途就是降维、去噪和图像生成。



## 类别

欠完备自编码器

> vanilla自编码器、多层自编码器、卷积子编码器CAE

正则编码器

> 稀疏子编码器、去噪子编码器DAE、收缩自编码器

变分自编码器VAE



## 欠完备自编码器

自编码器将数据作为输入并发现数据的一些潜在状态表示的模型（欠完备，洗漱，降噪，收缩等），将输入的数据转换为一个编码向量，其中每个维度表示一些学到的关于数据的属性。最重要的细节就是编码器网络为每个编码器维度输出单个值，而解码器网络随后接收这些值并尝试重构原始输入。



## 变分自编码器

变分子编码器(Variational Auto-Encoder,VAE)以概率的方式描述潜在空间观察。将给定输入的每个潜在属性表示为分布概率。

举个例子，中间的单值即为传统自编码器的方式，而变分自编码器使用概率属于来描述潜在属性，类似于GAN

<img src="https://mz-pico-1311932519.cos.ap-nanjing.myqcloud.com/image/image-20230309201215096.png" alt="image-20230309201215096" style="zoom:50%;" />

通过构造编码器模型来输出可能的范围(统计分布)，然后随机采样这些值供给解码器模型，实现了连续、平滑的潜在空间表示，对于潜在分布的所有采样，期望解码器模型能够准确准确重构输入， 因此，在潜在空间中彼此相邻的值应该有非常类似的重构对应。

希望通过构建隐变量$z$生成目标数据$x$，但是只能看到$x$，想要推断出$z$的特征，这就是贝叶斯概率：
$$
p(z|x)=\frac{p(x|z)p(z)}{p(x)}
$$
然而计算$p(x)$是一个非常复杂的过程：
$$
p(x)=\int p(x|z)p(z)dz
$$
它通常是一个复杂的分布，可以饮用变分推断来估计这个值，因此，VAE的理论基础就是变分与贝叶斯。不过可以使用另外一个分布$q(z|x)$来金丝$p(z|x)$，将其定义为具有可伸缩的分布，使用$KL$散度来度量两个概率分布的差值，
$$
\min KL(q(z|x)||p(x|z))
$$
推导结果，可以通过最大化下面的式子来最小化上述表达式：
$$
E_{q(x|z)}\log p(x|z)-KL(q(z|x)||p(z))
$$
第一个式子代表重构的可能性，第二个确保学习的分布$q$类似于真实的先验分布。

### 模型细节

- VAE编码器模型将输出描述在空间中每个维度分布的参数，假设先验符合正态分布，输出两个向量描述潜在状态的均值和方差。

- 构建一个真正的多元高斯模型，需要定义一个协方差矩阵来描述每个维度是如何相关的。做一个简化的假设，使协方差矩阵对角线上只有非零值，允许用简单的向量描述这些信息。
- 



# 代码理解

## 细节

##### loss.backward()理解

```python
criterion = nn.CrossEntropyLoss()
loss = criterion(outputs, labels)
loss.backward()
#即
loss = nn.CrossEntropyLoss(outputs, labels).backward()
```

将损失loss向输入侧进行反向传播，同时对于需要进行梯度计算的所有变量$x(requires_grad=True)$，计算梯度$\frac{d}{dx}loss$并将其累积到梯度$x.grad$中备用，即

$$
x.grad = x.grad+\frac{d}{dx}loss
$$

##### optimizer.step()理解

```python
optimizer = optim.SGD(net.parameters(), lr=0.001, momentum=0.9)  
optimizer.zero_grad()	#调用backward()之前要将梯度清零,因为使其在每个batch中不进行累计
optimizer.step()
```

是优化器对x的值进行更新，以随机梯度下降SGD为例子：

> 学习率(learning rate, lr)来控制步幅，即$x = x - lr * x.grad$，减号是因为沿着梯度反方向调整变量以减少cost

##### optimizer.zero_grad()理解

> Pytorch 为什么每一轮batch需要设置？

根据pytorch中的backward()函数的计算，当网络参量进行反馈时，梯度是被积累的而不是被替换掉；但是在每一个batch时毫无疑问并不需要将两个batch的梯度混合起来累积，因此这里就需要每个batch设置一遍zero_grad 了。

还可以补充的一点是，如果不是每一个batch就清除掉原有的梯度，而是比如说两个batch再清除掉梯度，这是一种变相提高batch_size的方法，对于计算机硬件不行，但是batch_size可能需要设高的领域比较适合，比如目标检测模型的训练
