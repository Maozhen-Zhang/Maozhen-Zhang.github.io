---
layout: post
title: 基础设置
date: 2023-02-28 12:52:00
description: 进行深度学习前的基础设置
tags: Code
categories: Deep-Learning
---



# 操作

## 本地和远程

```shell
#PATH
/Volumes/T7/Mac/Data
/home/zmz/dataset
```



## 显卡信息实时查看

```shell
#查看显卡信息
nvidia-smi
```

<img src="https://mz-pico-1311932519.cos.ap-nanjing.myqcloud.com/image/image-20221231144318992-20221231144635547.png" alt="image-20221231144318992" style="zoom: 100%;" />

```shell
#实时检测显卡状态
watch -n 0.1 -d nvidia-smi
```

# 参数设置

## GPU设置方法

GPU设置方法：`CUDA_VISIBLE_DEVICES`

<img src="https://mz-pico-1311932519.cos.ap-nanjing.myqcloud.com/image/98cb22f7c0644d939b1f66f53af3587b.png" alt="98cb22f7c0644d939b1f66f53af3587b" style="zoom:80%;" />

### 临时设置

一定要在第一次使用cuda前设置

```shell
Linux： export CUDA_VISIBLE_DEVICES=1
windows:  set CUDA_VISIBLE_DEVICES=1
```



### python 运行时设置

```python
import os
os.environ["CUDA_VISIBLE_DEVICES"] = "1"
```

或

```shell
CUDA_VISIBLE_DEVICES=1 python **.py	
```

### 永久设置

```shell
#linux:在~/.bashrc 的最后加上export CUDA_VISIBLE_DEVICES=1，然后source ~/.bashrc
#windows:打开我的电脑环境变量设置的地方，直接添加就行了。
```



# 训练的设置

## Batch的设置

小的`batch`对`testing acc`是有帮助的

|                                | 小batch size | 大 batch size |
| ------------------------------ | ------------ | ------------- |
| 每次update的速度(不含平行计算) | 快           | 慢            |
| 每次update的速度(含平行计算)   | 一样         | 几乎一样      |
| 训练一个epoch的时间            | 慢           | 快            |
| Gradient                       | Noisy        | Stable        |
| Optimization                   | 更好         | 不好          |
| 泛化能力                       | 更好         | 不好          |

## 学习率的设置

来源地址：[知乎链接](https://zhuanlan.zhihu.com/p/363645881)

在梯度比较陡的位置设置小的`Learning rate`

在梯度比较平坦的横轴设置大的`Learning rate`
$$
\theta_i^{t+1}\leftarrow \theta_i^{t}-\eta g_i^t\\
wehere \quad g_i^t=\frac{\partial L}{\partial \theta_i}|_\theta=\theta_i
$$
将学习率$$\eta$$ 特殊化，让$$\eta$$ 与$$\theta_i^t$$ 有关
$$
\theta_i^{t+1}\leftarrow \theta_i^{t}-\frac{\eta}{\sigma_i^t} g_i^t\\
$$
那么$$\sigma_i^t$$怎么取呢？

> 一种Root Mean Square的方法是：
>
> <img src="https://mz-pico-1311932519.cos.ap-nanjing.myqcloud.com/image/image-20230101120706092.png" alt="image-20230101120706092" style="zoom:50%;" />

每次的$$\sigma_i^t$$都是前面梯度的Root Mean Square，这种方法叫做`Adagrad`

>  实现坡度比较大时学习率较小以及坡度小时学习率较大的操作



但是对于图9的`error surface`来说，同样是横轴，

> 绿色箭头的梯度更大，需要使用小的学习率
>
> 红色箭头的梯度更小，需要使用大的学习率

<img src="https://mz-pico-1311932519.cos.ap-nanjing.myqcloud.com/image/image-20230101134058824.png" alt="image-20230101134058824" style="zoom:30%;" />

`RMSporp`方法就是为了解决这个问题：

<img src="https://mz-pico-1311932519.cos.ap-nanjing.myqcloud.com/image/image-20230101134304464.png" alt="image-20230101134304464" style="zoom:50%;" />

每次的$$\sigma_i^t$$都既考虑本次的梯度，也考虑之前的梯度。权重由$$\alpha$$决定

> $$\alpha$$越小，代表当前这个梯度$$g_i^t$$越重要
>
> $$\alpha$$越大，代表之前所有step的梯度$$g_i^0,g_i^1,...g_i^{t-1}$$越重要

当陡峭程度不同时，在陡的地方会增加sigma，减少学习率。在缓的地方会减小sigma，增大学习率。

<img src="https://mz-pico-1311932519.cos.ap-nanjing.myqcloud.com/image/image-20230101134608351.png" alt="image-20230101134608351" style="zoom:50%;" />

## Adam

图11所示为`RMSprop`的另一个改进版：Adam

主要有2个关键的变量：$$m_t,v_t$$

> $$m_t$$乘在了分子，相当于`momentum`，即考虑方向，又考虑大小
>
> $$v_t$$乘在分母上，相当于之前讨论的$$\sigma_t$$，不考虑方向，只考虑大小。

二者都是既考虑本次的梯度，也考虑之前的梯度。此外的$$\beta_1、\beta_2$$是超参数

> 这里解释为什么$$\hat m_t=\frac{m_t}{1-\beta_1^t}$$
>
> 前面time step的$$m_t$$可能较小，所以我们想$$\hat m_t$$不那么小，就需要除一个分母，让它变大一点
>
> 随着time step增加,$$m_t$$变大，$$\beta_1^t$$变小，$$1-\beta_1^t$$变大，所以$$\hat m_t$$就比较稳定，$$\hat v_t$$同理。

<img src="https://mz-pico-1311932519.cos.ap-nanjing.myqcloud.com/image/v2-e64b91c5fe3344c520e2d1387e31c423_1440w.webp" alt="v2-e64b91c5fe3344c520e2d1387e31c423_1440w" style="zoom:50%;" />





# 数据集

## MNIST-10

[^]: Yann LeCun, Corinna Cortes, and CJ Burges. Mnist handwritten digit database. ATT Labs [Online]. Available: http://yann.lecun.com/exdb/mnist, 2, 2010. 5

MNIST-10：该数据集由 10 个类组成，灰度图像为 28×28 像素。训练集中有60, 000张图片，测试集中有10, 000张图片。我们将数据标准化为均值 0 和方差 1。

## CIFAR-10/100

[^]: Alex Krizhevsky. Learning multiple layers of features from tiny images. Technical report, 2009. 5

该数据集由 32×32 像素的 RGB 图像组成。它包含 50, 000 个训练图像和 10, 000 个测试图像。它有两个变体：(a) CIFAR-10 图像是从 10 个类别中提取的，(b) CIFAR-100 图像是从 100 个类别中提取的。除非明确说明，否则我们遵循早期作品 [8、12] 中使用的标准数据增强技术（镜像/移位），然后跨通道标准化为标准高斯。

> [^8]: K. He, X. Zhang, S. Ren, and J. Sun. Deep residual learning for image recognition. In 2016 IEEE Conference on Computer Vision and Pattern Recognition (CVPR), pages 770–778, 2016. 1, 2, 5, 6, 7, 8, 13, 16
> [^12]: Gao Huang, Zhuang Liu, Laurens van der Maaten, and Kilian Q. Weinberger. Densely connected convolutional networks. In Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition (CVPR), July 2017. 2, 5, 6, 7, 8, 13

## Imagenet-1000 

[^]: Olga Russakovsky, Jia Deng, Hao Su, Jonathan Krause, Sanjeev Satheesh, Sean Ma, Zhiheng Huang, Andrej Karpathy, Aditya Khosla, Michael Bernstein, Alexander C. Berg, and Li Fei-Fei. ImageNet Large Scale Visual Recognition Challenge. International Journal of Computer Vision (IJCV), 115(3):211252, 2015. 5

它是流行的 ILSVRC 2012 分类数据集。这个 1000 路分类数据集包含 128 万张训练图像和 50, 000 张验证图像。我们遵循标准数据增强（镜像、调整大小和裁剪形状 224 × 224）进行训练和单一裁剪进行测试。与以前的工作类似，我们报告验证集的结果。